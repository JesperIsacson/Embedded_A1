{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 2: Model Compression\n",
    "# 1.Compress your new model from problem 1 by converting it into a TF Lite model.\n",
    "# 2.Use the TensorFlow Interpreter to load your compressed model in (1) and classify new images.\n",
    "# 3.How big is your compressed model compared to the pre-compressed model in problem 1?\n",
    "# 4.How quickly does your compressed model classify an image?\n",
    "# 5.How much did compressing the model affect classification accuracy? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "labels = []\n",
    "classes = 43\n",
    "cur_path = os.getcwd()\n",
    "data_directory = './archive'\n",
    "\n",
    "for i in range(classes):\n",
    "    path = os.path.join(data_directory, 'Train', str(i))\n",
    "    images = os.listdir(path)\n",
    "    for a in images:\n",
    "        try:\n",
    "            image = Image.open(os.path.join(path, a))\n",
    "            image = image.resize((30, 30))\n",
    "            image = np.array(image)\n",
    "            data.append(image)\n",
    "            labels.append(i)\n",
    "        except:\n",
    "            print(\"Error loading image\")\n",
    "\n",
    "data = np.array(data)\n",
    "data = tf.data.Dataset.from_tensor_slices(data)\n",
    "data = data.shuffle(buffer_size=len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the model (let's use the saved model from the previous exercise)\n",
    "import_path = os.path.join(os.getcwd(),'saved_models','model')\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(import_path) # path to the SavedModel directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot set tensor: Got value of type UINT8 but expected type FLOAT32 for input 0, name: serving_default_keras_layer_input:0 ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32me:\\Vs Skola\\JU\\Embedded_A1\\Assigment 2\\problem2.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Vs%20Skola/JU/Embedded_A1/Assigment%202/problem2.ipynb#X15sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m converter\u001b[39m.\u001b[39minference_output_type \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mint8  \u001b[39m# or tf.uint8\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Vs%20Skola/JU/Embedded_A1/Assigment%202/problem2.ipynb#X15sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m converter\u001b[39m.\u001b[39mrepresentative_dataset \u001b[39m=\u001b[39m representative_data_gen\n\u001b[1;32m---> <a href='vscode-notebook-cell:/e%3A/Vs%20Skola/JU/Embedded_A1/Assigment%202/problem2.ipynb#X15sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m tflite_model \u001b[39m=\u001b[39m converter\u001b[39m.\u001b[39;49mconvert()\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Vs%20Skola/JU/Embedded_A1/Assigment%202/problem2.ipynb#X15sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# Let's create the folder \"saved_tflite_models\" and store the TFLite models there\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/e%3A/Vs%20Skola/JU/Embedded_A1/Assigment%202/problem2.ipynb#X15sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m os\u001b[39m.\u001b[39mmakedirs(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(os\u001b[39m.\u001b[39mgetcwd(),\u001b[39m'\u001b[39m\u001b[39msaved_tflite_models\u001b[39m\u001b[39m'\u001b[39m), exist_ok \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\lite\\python\\lite.py:930\u001b[0m, in \u001b[0;36m_export_metrics.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    927\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(convert_func)\n\u001b[0;32m    928\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    929\u001b[0m   \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 930\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_convert_and_export_metrics(convert_func, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\lite\\python\\lite.py:908\u001b[0m, in \u001b[0;36mTFLiteConverterBase._convert_and_export_metrics\u001b[1;34m(self, convert_func, *args, **kwargs)\u001b[0m\n\u001b[0;32m    906\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save_conversion_params_metric()\n\u001b[0;32m    907\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mprocess_time()\n\u001b[1;32m--> 908\u001b[0m result \u001b[39m=\u001b[39m convert_func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    909\u001b[0m elapsed_time_ms \u001b[39m=\u001b[39m (time\u001b[39m.\u001b[39mprocess_time() \u001b[39m-\u001b[39m start_time) \u001b[39m*\u001b[39m \u001b[39m1000\u001b[39m\n\u001b[0;32m    910\u001b[0m \u001b[39mif\u001b[39;00m result:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\lite\\python\\lite.py:1213\u001b[0m, in \u001b[0;36mTFLiteSavedModelConverterV2.convert\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1208\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1209\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_debug_info \u001b[39m=\u001b[39m _get_debug_info(\n\u001b[0;32m   1210\u001b[0m       _convert_debug_info_func(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_trackable_obj\u001b[39m.\u001b[39mgraph_debug_info),\n\u001b[0;32m   1211\u001b[0m       graph_def)\n\u001b[1;32m-> 1213\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_convert_from_saved_model(graph_def)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\lite\\python\\lite.py:1097\u001b[0m, in \u001b[0;36mTFLiteConverterBaseV2._convert_from_saved_model\u001b[1;34m(self, graph_def)\u001b[0m\n\u001b[0;32m   1094\u001b[0m converter_kwargs\u001b[39m.\u001b[39mupdate(quant_mode\u001b[39m.\u001b[39mconverter_flags())\n\u001b[0;32m   1096\u001b[0m result \u001b[39m=\u001b[39m _convert_saved_model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconverter_kwargs)\n\u001b[1;32m-> 1097\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimize_tflite_model(\n\u001b[0;32m   1098\u001b[0m     result, quant_mode, quant_io\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexperimental_new_quantizer)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\lite\\python\\convert_phase.py:215\u001b[0m, in \u001b[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m error:\n\u001b[0;32m    214\u001b[0m   report_error_message(\u001b[39mstr\u001b[39m(error))\n\u001b[1;32m--> 215\u001b[0m   \u001b[39mraise\u001b[39;00m error \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\lite\\python\\convert_phase.py:205\u001b[0m, in \u001b[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m    203\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    204\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    206\u001b[0m   \u001b[39mexcept\u001b[39;00m ConverterError \u001b[39mas\u001b[39;00m converter_error:\n\u001b[0;32m    207\u001b[0m     \u001b[39mif\u001b[39;00m converter_error\u001b[39m.\u001b[39merrors:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\lite\\python\\lite.py:868\u001b[0m, in \u001b[0;36mTFLiteConverterBase._optimize_tflite_model\u001b[1;34m(self, model, quant_mode, quant_io)\u001b[0m\n\u001b[0;32m    866\u001b[0m   q_bias_type \u001b[39m=\u001b[39m quant_mode\u001b[39m.\u001b[39mbias_type()\n\u001b[0;32m    867\u001b[0m   q_allow_float \u001b[39m=\u001b[39m quant_mode\u001b[39m.\u001b[39mis_allow_float()\n\u001b[1;32m--> 868\u001b[0m   model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_quantize(model, q_in_type, q_out_type, q_activations_type,\n\u001b[0;32m    869\u001b[0m                          q_bias_type, q_allow_float)\n\u001b[0;32m    871\u001b[0m m_in_type \u001b[39m=\u001b[39m in_type \u001b[39mif\u001b[39;00m in_type \u001b[39melse\u001b[39;00m _dtypes\u001b[39m.\u001b[39mfloat32\n\u001b[0;32m    872\u001b[0m m_out_type \u001b[39m=\u001b[39m out_type \u001b[39mif\u001b[39;00m out_type \u001b[39melse\u001b[39;00m _dtypes\u001b[39m.\u001b[39mfloat32\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\lite\\python\\lite.py:612\u001b[0m, in \u001b[0;36mTFLiteConverterBase._quantize\u001b[1;34m(self, result, input_type, output_type, activations_type, bias_type, allow_float)\u001b[0m\n\u001b[0;32m    608\u001b[0m calibrate_quantize \u001b[39m=\u001b[39m _calibrator\u001b[39m.\u001b[39mCalibrator(result,\n\u001b[0;32m    609\u001b[0m                                             custom_op_registerers_by_name,\n\u001b[0;32m    610\u001b[0m                                             custom_op_registerers_by_func)\n\u001b[0;32m    611\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_experimental_calibrate_only \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_new_quantizer:\n\u001b[1;32m--> 612\u001b[0m   calibrated \u001b[39m=\u001b[39m calibrate_quantize\u001b[39m.\u001b[39;49mcalibrate(\n\u001b[0;32m    613\u001b[0m       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrepresentative_dataset\u001b[39m.\u001b[39;49minput_gen)\n\u001b[0;32m    615\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_experimental_calibrate_only:\n\u001b[0;32m    616\u001b[0m   \u001b[39mreturn\u001b[39;00m calibrated\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\lite\\python\\convert_phase.py:215\u001b[0m, in \u001b[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m error:\n\u001b[0;32m    214\u001b[0m   report_error_message(\u001b[39mstr\u001b[39m(error))\n\u001b[1;32m--> 215\u001b[0m   \u001b[39mraise\u001b[39;00m error \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\lite\\python\\convert_phase.py:205\u001b[0m, in \u001b[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m    203\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    204\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    206\u001b[0m   \u001b[39mexcept\u001b[39;00m ConverterError \u001b[39mas\u001b[39;00m converter_error:\n\u001b[0;32m    207\u001b[0m     \u001b[39mif\u001b[39;00m converter_error\u001b[39m.\u001b[39merrors:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\lite\\python\\optimize\\calibrator.py:226\u001b[0m, in \u001b[0;36mCalibrator.calibrate\u001b[1;34m(self, dataset_gen)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[39m@convert_phase\u001b[39m(Component\u001b[39m.\u001b[39mOPTIMIZE_TFLITE_MODEL, SubComponent\u001b[39m.\u001b[39mCALIBRATE)\n\u001b[0;32m    217\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcalibrate\u001b[39m(\u001b[39mself\u001b[39m, dataset_gen):\n\u001b[0;32m    218\u001b[0m   \u001b[39m\"\"\"Calibrates the model with specified generator.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \n\u001b[0;32m    220\u001b[0m \u001b[39m  Returns:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[39m    dataset_gen: A generator that generates calibration samples.\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 226\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_feed_tensors(dataset_gen, resize_input\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    227\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_calibrator\u001b[39m.\u001b[39mCalibrate()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\lite\\python\\optimize\\calibrator.py:138\u001b[0m, in \u001b[0;36mCalibrator._feed_tensors\u001b[1;34m(self, dataset_gen, resize_input)\u001b[0m\n\u001b[0;32m    136\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_calibrator\u001b[39m.\u001b[39mFeedTensor(input_array, signature_key)\n\u001b[0;32m    137\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 138\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_calibrator\u001b[39m.\u001b[39;49mFeedTensor(input_array)\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot set tensor: Got value of type UINT8 but expected type FLOAT32 for input 0, name: serving_default_keras_layer_input:0 "
     ]
    }
   ],
   "source": [
    "#converter.allow_custom_ops = True\n",
    "def representative_data_gen():\n",
    "  for input_value in data.batch(1).take(1):\n",
    "    # Model has only one input so each data point has one element.\n",
    "    yield [input_value]\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,  # Enable TensorFlow Lite ops.\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS,  # Enable TensorFlow ops.\n",
    "]\n",
    "converter.inference_input_type = tf.int8  # or tf.uint8\n",
    "converter.inference_output_type = tf.int8  # or tf.uint8\n",
    "converter.representative_dataset = representative_data_gen\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Let's create the folder \"saved_tflite_models\" and store the TFLite models there\n",
    "os.makedirs(os.path.join(os.getcwd(),'saved_tflite_models'), exist_ok = True)\n",
    "\n",
    "# Save the model\n",
    "tflite_model_path = os.path.join(os.getcwd(),'saved_tflite_models','model.tflite')\n",
    "with open(tflite_model_path, 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify all test ds here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GB: 1.468\n",
      "GB: 1.429\n"
     ]
    }
   ],
   "source": [
    "def getfoldersize(path):\n",
    "  total_size = 0\n",
    "  for dirpath, dirnames, filenames in os.walk(path):\n",
    "      for f in filenames:\n",
    "          fp = os.path.join(dirpath, f)\n",
    "          # skip if it is symbolic link\n",
    "          if not os.path.islink(fp):\n",
    "              total_size += os.path.getsize(fp)\n",
    "\n",
    "  total_size /= (1024 ** 3)\n",
    "  total_size = round(total_size, 3)\n",
    "  return total_size\n",
    "\n",
    "old_model_size = getfoldersize(os.path.join(os.getcwd(),'saved_models','model'))\n",
    "new_model_size = getfoldersize(os.path.join(os.getcwd(),'saved_tflite_models'))\n",
    "\n",
    "print(\"GB: \" + str(old_model_size))\n",
    "print(\"GB: \" + str(new_model_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "# Classify 1 image here\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compere old model and new model acc here (need to load and deload old model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
