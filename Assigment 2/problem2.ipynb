{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem 2: Model Compression\n",
    "# 1.Compress your new model from problem 1 by converting it into a TF Lite model.\n",
    "# 2.Use the TensorFlow Interpreter to load your compressed model in (1) and classify new images.\n",
    "# 3.How big is your compressed model compared to the pre-compressed model in problem 1?\n",
    "# 4.How quickly does your compressed model classify an image?\n",
    "# 5.How much did compressing the model affect classification accuracy? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow_model_optimization # Never used but tried then uninstalled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "from PIL import Image\n",
    "import cv2 as cv\n",
    "import pandas as pd\n",
    "#import tensorflow_model_optimization as tfmot\n",
    "#import re\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_data = []\n",
    "Train_labels = []\n",
    "classes = 43\n",
    "batch_size = 32\n",
    "data_directory = './archive'\n",
    "\n",
    "for i in range(classes):\n",
    "    path = os.path.join(data_directory, 'Train', str(i))\n",
    "    images = os.listdir(path)\n",
    "    for a in images:\n",
    "        try:\n",
    "            batch_images = Image.open(os.path.join(path, a))\n",
    "            batch_images = batch_images.resize((30, 30))\n",
    "            batch_images = np.array(batch_images, dtype=np.float32)\n",
    "            Train_data.append(batch_images)\n",
    "            Train_labels.append(i)\n",
    "        except:\n",
    "            print(\"Error loading image\")\n",
    "\n",
    "Train_data = np.array(Train_data)\n",
    "#Train_data = Train_data.shuffle(buffer_size=len(Train_data))\n",
    "Train_labels = np.array(Train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf.convert_to_tensor(Train_data)\n",
    "y_train = tf.convert_to_tensor(Train_labels)\n",
    "y_train = to_categorical(y_train, 43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pruning test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Convert the model\\nimport_path = os.path.join(os.getcwd(),'saved_models','model')\\npruning = tf.keras.models.load_model(import_path) \""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Convert the model\n",
    "import_path = os.path.join(os.getcwd(),'saved_models','model')\n",
    "pruning = tf.keras.models.load_model(import_path) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# due to downloaded model being a KerasLayers without pruning enabled we couldnt get it to run\\nprune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude(pruning)\\n\\n\\n# Compute end step to finish pruning after 2 epochs.\\nbatch_size = 32\\nepochs = 2\\nvalidation_split = 0.1 # 10% of training set will be used for validation set. \\n\\nnum_images = Train_data.shape[0] * (1 - validation_split)\\nend_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\\n\\n# Define model for pruning.\\npruning_params = {\\n      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.00,\\n                                                               final_sparsity=0.50,\\n                                                               begin_step=0,\\n                                                               end_step=end_step)\\n}\\n\\nmodel_for_pruning = tfmot.sparsity.keras.prune_low_magnitude(pruning, **pruning_params)\\n# prune_low_magnitude = tfmot.sparsity.keras.strip_pruning(pruning)\\n# re train for 2 epochs?\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# due to downloaded model being a KerasLayers without pruning enabled we couldnt get it to run\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude(pruning)\n",
    "\n",
    "\n",
    "# Compute end step to finish pruning after 2 epochs.\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "validation_split = 0.1 # 10% of training set will be used for validation set. \n",
    "\n",
    "num_images = Train_data.shape[0] * (1 - validation_split)\n",
    "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "# Define model for pruning.\n",
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.00,\n",
    "                                                               final_sparsity=0.50,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "}\n",
    "\n",
    "model_for_pruning = tfmot.sparsity.keras.prune_low_magnitude(pruning, **pruning_params)\n",
    "# prune_low_magnitude = tfmot.sparsity.keras.strip_pruning(pruning)\n",
    "# re train for 2 epochs?\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the model\n",
    "import_path = os.path.join(os.getcwd(),'saved_models','model')\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(import_path) # path to the SavedModel directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tried to implement Post-training integer quantization\n",
    "# We tried alot of diffrent settings but it seems the model we chose from the tfhub \n",
    "# cant be compressed that well not with quantization atleast\n",
    "# Followed https://www.tensorflow.org/lite/performance/model_optimization \n",
    "# and from that https://www.tensorflow.org/lite/performance/post_training_integer_quant\n",
    "# looked at https://www.tensorflow.org/lite/performance/post_training_quantization for representative dataset\n",
    "# This reduced Acc of the TfLite model to 3.8% from 45%\n",
    "\n",
    "\"\"\"def representative_data_gen():\n",
    "  for input_value in Train_data.batch(1).take(100):\n",
    "    # Model has only one input so each data point has one element.\n",
    "    yield [input_value]\n",
    "\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS, # Enable TensorFlow ops.\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS_INT8 \n",
    "]\n",
    "converter.representative_dataset = representative_data_gen\"\"\"\n",
    "# above didnt seem to help the compression despite alot of resourses claiming it would\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS, # Enable TensorFlow ops.\n",
    "]\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Let's create the folder \"saved_tflite_models\" and store the TFLite models there\n",
    "os.makedirs(os.path.join(os.getcwd(),'saved_tflite_models'), exist_ok = True)\n",
    "\n",
    "# Save the model\n",
    "tflite_model_path = os.path.join(os.getcwd(),'saved_tflite_models','model.tflite')\n",
    "with open(tflite_model_path, 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"./archive/Test.csv\")\n",
    "labels = test_data[\"ClassId\"].values\n",
    "filenames = test_data[\"Path\"].values\n",
    "\n",
    "Test_data = []\n",
    "\n",
    "for filename in filenames:\n",
    "    img_path = os.path.join(\"./archive\", filename)\n",
    "    batch_images = Image.open(img_path)\n",
    "    batch_images = batch_images.resize((30,30))\n",
    "    batch_images = np.uint8(batch_images)\n",
    "    Test_data.append(np.array(batch_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_data =  tf.convert_to_tensor(Test_data)\n",
    "Test_ds = tf.data.Dataset.from_tensor_slices(Test_data)\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "Test_ds = Test_ds.batch(batch_size).prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(\"./saved_tflite_models/model.tflite\")\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "input_shape = input_details[0]['shape']\n",
    "input = input_details[0]['index']\n",
    "output = output_details[0]['index']\n",
    "\n",
    "shape_1 = input_shape[1]\n",
    "shape_2 = input_shape[2]\n",
    "shape_3 = input_shape[3]\n",
    "\n",
    "# Resize to allow batches to speed up time for the test dataset\n",
    "interpreter.resize_tensor_input(input, [batch_size, shape_1, shape_2, shape_3])\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify all test ds here\n",
    "pred_probs = []\n",
    "for batch_images in Test_ds:\n",
    "  if(batch_images.shape[0]< batch_size): # crashes on last one otherwise (could resize and allocate tensors again but have enough data)\n",
    "    break\n",
    "  batch_images = np.float32(batch_images) # not 100% sure this is the right approach\n",
    "  interpreter.set_tensor(input_details[0]['index'], batch_images)\n",
    "\n",
    "  interpreter.invoke()\n",
    "  for pred_out in interpreter.get_tensor(output):\n",
    "    pred_probs.append(pred_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(np.argmax(pred_probs, axis=1))\n",
    "pred_df.to_csv(\"preds_tflite.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old GB: 1.468\n",
      "New GB: 1.446\n"
     ]
    }
   ],
   "source": [
    "def getfoldersize(path):\n",
    "  total_size = 0\n",
    "  for dirpath, dirnames, filenames in os.walk(path):\n",
    "      for f in filenames:\n",
    "          fp = os.path.join(dirpath, f)\n",
    "          # skip if it is symbolic link\n",
    "          if not os.path.islink(fp):\n",
    "              total_size += os.path.getsize(fp)\n",
    "\n",
    "  total_size /= (1024 ** 3)\n",
    "  total_size = round(total_size, 3)\n",
    "  return total_size\n",
    "\n",
    "old_model_size = getfoldersize(os.path.join(os.getcwd(),'saved_models','model'))\n",
    "new_model_size = getfoldersize(os.path.join(os.getcwd(),'saved_tflite_models'))\n",
    "\n",
    "print(\"Old GB: \" + str(old_model_size))\n",
    "print(\"New GB: \" + str(new_model_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One image took 0.719 sec\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(\"./saved_tflite_models/model.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "input_shape = input_details[0]['shape']\n",
    "input = input_details[0]['index']\n",
    "output = output_details[0]['index']\n",
    "\n",
    "images = cv.imread(\"./archive/Test/00002.png\")\n",
    "images = cv.cvtColor(images, cv.COLOR_BGR2RGB)\n",
    "resized_image = cv.resize(images, input_shape[1:3])\n",
    "input_data = np.expand_dims(resized_image, axis=0)\n",
    "input_data = np.float32(input_data)\n",
    "\n",
    "# This is the time per interpreted image\n",
    "start = time.time()\n",
    "\n",
    "interpreter.set_tensor(input, input_data)\n",
    "interpreter.invoke()\n",
    "output_data = interpreter.get_tensor(output)\n",
    "\n",
    "end = time.time()\n",
    "print(\"One image took \" + str(round(end - start, 3)) + \" sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compere old model and new model acc here (need to load and deload old model)\n",
    "not_tflite_preds = pd.read_csv(\"preds.csv\")\n",
    "tflite_preds = pd.read_csv(\"preds_tflite.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lite model Acc: \n",
      "0.45\n",
      "Non model Acc: \n",
      "0.45\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i, lite in enumerate(tflite_preds.iterrows()):\n",
    "  if(lite[1].values[-1] == labels[i]):\n",
    "    correct += 1\n",
    "print(\"Lite model Acc: \\n\" + str(round(correct/len(tflite_preds), 3)))\n",
    "\n",
    "correct = 0\n",
    "for i, not_lite in enumerate(not_tflite_preds.iterrows()):\n",
    "  if(not_lite[1].values[-1] == labels[i]):\n",
    "    correct += 1\n",
    "\n",
    "print(\"Non model Acc: \\n\" + str(round(correct/len(not_tflite_preds), 3)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
